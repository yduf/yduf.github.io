---
title: ONNX
published: true
tags: NN-model c++ microsoft
toc: true
---
> Convert deep learning frameworks such as PyTorch and TensorFlow/Keras and run them directly from c++ - [github](https://github.com/microsoft/onnxruntime?tab=readme-ov-file#get-started--resources)

## [ONNX model files structure](https://chatgpt.com/share/693fbc62-1614-800d-914d-da800018305f)

ONNX files can be a bit confusing at first because a single model can be represented by one file or by a small set of related files, depending on how it was exported. 

## [OpenCV DNN]({% post_url 2023-03-10-opencv-dnn-module %})

supports loading many popular deep learning frameworks such as TensorFlow, (Py)Torch, DarkNet, Caffe, [**ONNX**](https://learnopencv.com/deep-learning-with-opencvs-dnn-module-a-definitive-guide/). 

## ONNX C++ Runtime
**Windows distributions of this project may collect usage data and send it to Microsoft**

### [What is ONNX C++ Runtime?](https://chatgpt.com/share/6923559e-7230-800d-8ebb-6d88eb0a32b2)

It is simply the C++ API of ONNX Runtime that allows you to:
- Load ONNX models in a C++ program
- Run inference on them
- Feed inputs and fetch outputs
- Configure execution providers (CPU, CUDA, etc.)
- Optimize models

Essentially, you can embed fast ML inference inside native C++ applications.
