---
published: true
title: 'Word2Vec: A Word is Worth a Thousand Vectors'
tags: word2vec AI LLM
---
> That word vectors represent much of the information available in a dictionary definition is a convenient and almost miraculous side effect of trying to predict the context of a word. - [article](https://multithreaded.stitchfix.com/blog/2015/03/11/word-is-worth-a-thousand-vectors/)

[there is a strong conceptual relation between bag-of-word representations of old days and word2vec.](https://news.ycombinator.com/item?id=40073698) - compare evolutio from document vectors and term vectors to dense vector similar to word2vec.
	- [Neural Word Embedding as Implicit Matrix Factorization](https://proceedings.neurips.cc/paper_files/paper/2014/file/feab05aa91085b7a8012516bc3533958-Paper.pdf)

- [Transforming everything to vectors with Deep Learning: from Word2Vec, Node2Vec, to Code2Vec and Data2Vec](https://tungmphung.com/transforming-everything-to-vectors-with-deep-learning-from-word2vec-node2vec-to-code2vec-and-data2vec/)

- [word2vec](https://code.google.com/archive/p/word2vec/)

- [code2vec](https://code2vec.org/)

- [chess2vec](https://news.ycombinator.com/item?id=20711585)
	- [Learning Vector Representations for Chess](http://www.berkkapicioglu.com/wp-content/uploads/2018/11/chess2vec_nips_2018_short.pdf)
