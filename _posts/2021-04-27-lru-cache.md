---
published: true
title: LRU Cache
tags: algorithm cache leetcode random
---
> If you have a tight loop, LRU is going to be perfect as long as the loop fits in cache, but it's going to cause a miss every time if the loop doesn't fit. A random eviction policy degrades gracefully as the loop gets too big. - [Caches: LRU v. random](https://danluu.com/2choices-eviction/) / [HN](https://news.ycombinator.com/item?id=39093109)

### see also

- [The power of two random choices](https://brooker.co.za/blog/2012/01/17/two-random.html) / [HN](https://news.ycombinator.com/item?id=39283595) / [twitter](https://twitter.com/GrantSlatton/status/1754912113246798036) - show that considering only the best of 2 random pick for cache eviction, gives pretty good results. / this would work as well for other job, like [load balancing](https://news.ycombinator.com/item?id=37143376) among N servers.
- [Linux Kernel: The multi-generational LRU](https://lwn.net/Articles/851184/) / [HN](https://news.ycombinator.com/item?id=26858752) 
- [146. LRU Cache](https://leetcode.com/problems/lru-cache/)
- [Why Aren't We Sieve-Ing?](https://news.ycombinator.com/item?id=38911740) - SIEVE is an eviction algorithm, a way of deciding which cached item to toss out when a new one needs to be put in.
- [Caffeine](https://adriacabeza.github.io/2024/07/12/caffeine-cache.html) / [HN](https://news.ycombinator.com/item?id=42907488) -  high performance caching library