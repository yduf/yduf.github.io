---
published: true
title: Llama (ChatGPT @Home)
tags: LLM NN test algorithm
---
> A 2 files on prem LLM. - [Intro to Large Language Models](https://www.youtube.com/watch?v=zjkBMFhNj_g&t=2867s) / [Llama In My Living Room](https://www.youtube.com/watch?v=l-sZyfFX4F0)

### [Llama vs ChatGPT](https://duckduckgo.com/?t=lm&q=chatgpt+vs+llama2&ia=web)
- [ChatGPT vs Llama2](https://contentdetector.ai/articles/chatgpt-vs-llama2) - A Detailed Statistical Comparison

- [How To Run Llama 2 on Anything](https://medium.com/timesurge-labs/how-to-run-llama-2-on-anything-79fc007e2518)
	- [Run a Chatgpt-like Chatbot on a Single GPU with ROCm ](https://huggingface.co/blog/chatbot-amd-gpu)
	- [ Hardware requirements for Llama 2 #425 ](https://github.com/facebookresearch/llama/issues/425#issuecomment-1646923068) - [llama-2-13b-chat.ggmlv3.q4_0.bin](https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF), llama-2-13b-chat.ggmlv3.q8_0.bin and llama-2-70b-chat.ggmlv3.q4_0.bin from [TheBloke](https://huggingface.co/TheBloke).
    	- [`huggingface-cli`](https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF#on-the-command-line-including-multiple-files-at-once) `download TheBloke/Llama-2-13B-chat-GGUF llama-2-13b-chat.Q4_K_M.gguf`
        - `./main -ngl 32  -m /home/yves/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q4_K_M.gguf --color  --temp 0.7 --repeat_penalty 1.1 -n -1 -i -ins`
    - [Cheapest hardware to run Llama 2 70B](https://news.ycombinator.com/item?id=37067933) - Anything with 64GB of memory will run a quantized 70B model. What else you need depends on what is acceptable speed for you.

### [Llama.cpp](https://github.com/ggerganov/llama.cpp)

> The main goal of llama.cpp is to run the LLaMA model using 4-bit integer quantization on a MacBook

{% highlight bash %}
$ git clone https://github.com/ggerganov/llama.cpp
$ cd llama.cpp
# https://github.com/ggerganov/llama.cpp#hipblas
$ make LLAMA_HIPBLAS=1 #  BLAS acceleration on HIP-supported AMD GPUs (ROCm) 
{% endhighlight %}

### [Download Model](https://ai.meta.com/resources/models-and-libraries/llama-downloads/)

[Already quantized/converted model](https://github.com/ggerganov/llama.cpp#obtaining-and-using-the-facebook-llama-2-model)
- [Llama 2 7B - GGUF ](https://huggingface.co/TheBloke/Llama-2-7B-GGUF)

- [Code Llama](https://www.codecademy.com/article/how-to-use-code-llama)
	- [Introducing Code Llama, a state-of-the-art large language model for coding](https://ai.meta.com/blog/code-llama-large-language-model-coding/) / [huggingface](https://huggingface.co/blog/codellama)
    
- [Magicoder]()
    
### [Running Chat](https://github.com/ggerganov/llama.cpp#interactive-mode)

{% highlight bash %}
$ ./main -m ./models/7B/llama-2-7b.Q4_K_M.gguf  --repeat_penalty 1.0 -ngl 100 --color -i -r "User:" -f prompts/chat-with-bob.txt

User:Where is Bratislava ?
Bob: Bratislava is the capital of Slovakia, which is a country in the European Union.
User:When was it founded ?
Bob: Bratislava was founded in 1536, by King Ferdinand I. # Beware of LLM answer...

{% endhighlight %}

see
- [ Offloading 0 layers to GPU #1956 ](https://github.com/ggerganov/llama.cpp/issues/1956) - use `-ngl 100` to force using VRAM
- [Computer Hardware Required to Run LLaMA AI Model Locally (GPU, CPU, RAM, SSD)](https://www.hardware-corner.net/guides/computer-to-run-llama-ai-model/)

### [UI ?](https://duckduckgo.com/?t=lm&q=a+ui+like+chatgpt+for+llama.cpp&ia=web)

- [gpt-llama.cpp](https://github.com/keldenl/gpt-llama.cpp#gpt-llamacpp) - Replace OpenAi's GPT APIs with llama.cpp's supported models locally 
- [LlamaGPT](https://github.com/getumbrel/llama-gpt#llamagpt) -  self-hosted, offline, ChatGPT-like chatbot, powered by Llama 2. 100% private, with no data leaving your device. 


### see also
- [Let's build GPT: from scratch, in code, spelled out.](https://www.youtube.com/watch?v=kCc8FmEb1nY)
	- [Let's build the GPT Tokenizer](https://www.youtube.com/watch?v=zduSFxRajkE)
    	- [tiktokenizer]( https://tiktokenizer.vercel.app) - online syntax coloring token extraction
        - [Byte Pair algorithm](https://en.wikipedia.org/wiki/Byte_pair_encoding) - identify most used pairs in a sequence
	- [Let's reproduce GPT-2 (124M)](https://www.youtube.com/watch?v=l8pRSuU81PU)
- [	Llama from scratch, or how to implement a paper without crying](https://news.ycombinator.com/item?id=37059479)
- [The Geometry of Truth: Do LLM's Know True and False](https://news.ycombinator.com/item?id=37945961)
- [whisper.cpp](https://github.com/ggerganov/whisper.cpp#whispercpp) - High-performance inference of OpenAI's Whisper automatic speech recognition (ASR) model
