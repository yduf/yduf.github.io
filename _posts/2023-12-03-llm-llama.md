---
published: true
title: Llama (ChatGPT @Home)
tags: LLM NN
---
> A 2 files on prem LLM. - [Intro to Large Language Models](https://www.youtube.com/watch?v=zjkBMFhNj_g&t=2867s)

- [How To Run Llama 2 on Anything](https://medium.com/timesurge-labs/how-to-run-llama-2-on-anything-79fc007e2518)
	- [Run a Chatgpt-like Chatbot on a Single GPU with ROCm ](https://huggingface.co/blog/chatbot-amd-gpu)

### [Llama.cpp](https://github.com/ggerganov/llama.cpp)

> The main goal of llama.cpp is to run the LLaMA model using 4-bit integer quantization on a MacBook

{% highlight cpp %}
$ git clone https://github.com/ggerganov/llama.cpp
$ cd llama.cpp
# https://github.com/ggerganov/llama.cpp#hipblas
$ make LLAMA_HIPBLAS=1 #  BLAS acceleration on HIP-supported AMD GPUs (ROCm) 
{% endhighlight %}

### [Download Model](https://ai.meta.com/resources/models-and-libraries/llama-downloads/)

### Running Chat



### see also
- [Let's build GPT: from scratch, in code, spelled out.](https://www.youtube.com/watch?v=kCc8FmEb1nY)
- [	Llama from scratch, or how to implement a paper without crying](https://news.ycombinator.com/item?id=37059479)
- [The Geometry of Truth: Do LLM's Know True and False](https://news.ycombinator.com/item?id=37945961)
